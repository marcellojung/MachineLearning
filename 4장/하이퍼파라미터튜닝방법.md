## 하이퍼파라미터 튜닝 수행 방법


### Grid Search
 - 그라디언트 부스팅 기반 알고리즘은 튜이할 파라미터개수가 많고 범위도 넣어서 경우의 수가 너무 많다. 굉장히 오랜 시간이 필요 
 - 트리까지는 괜찮았는데 GBM 쪽이 나오면서 너무 오래걸림. 
### Random Search
 - 그리드서치를 랜덤 선택. 랜덤한 선택으로 최적에 제한된다. 
## Bayesian Optimization ***
 - 가능한 최소의 시도로 최적의 답을 찾아야 할 경우 수행 
 - 베이지안 최적화는 미지의 함수가 반환하는 값의 최소 또는 최대값 만드는 최적해를 짧은 반복을 통해 찾아내는 방식 
 - 사후 모델을 개선해나가면서 갱신하면서 최적 함수를 도출 
 ### 베이지안 최적화 방법
 - 최초에는 랜덤하게 하이퍼 파라미터들을 샘플링하여 성능 결과를 관측
 - 관측된 값을 기반으로 대체 모델은 최적 함수를 예측 추정 
 - 획득 함수에서 다음으로 관측할 하이퍼 파라미터 관측 
 - 해당 하이퍼파라미터로 목표 최적값에 다가가게 됨 
  ### 주요 패키지
  - HyperOpt : 좀 더 직관적인 API 
    - 입력값 범위 : search_space={'x':hp.quniform('x',5,15,1)}
    - 목적함수 : Objective_func(search_space): return {'loss':x**2+y*20,'stauts':STATUS_OK}
    - 목적함수 반환 최소값 유추 : best = fmin(fn=bjective_func, space=search_space,algo=algo,max_evals=5,trials=trials)
  - Bayesian optimization
  - Optuna 
### 수동 튜닝 
 - 경험적.. 도메인지식 