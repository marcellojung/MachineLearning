## 앙상블 모델

### 앙상블 개요
 - 단일분류기보다 우수한 효과를 내기 위해 여러 개의 분류기를 생성하고 그 예측을 결합하는 방법
 - 개별 분류기보다 더 좋은 정확도를 달성할 수 있음
 - 과적합의 문제를 해결하고 장점인 정확도를 높일 수 있다!

### 앙상블 학습의 종류
   - 보팅(Voting) : 서로다른 알고리즘을 가진 분류기가 같은 데이터셋 학습 -> 최종 보팅 결과에 따라 예측 
    
    - 하드보팅(다수결), 소프트보팅(평균) 두 종류가 있다. 

   - 배깅(Bagging) : 알고리즘이 똑같다, 단 학습하는데이터가 다르다. 데이터 샘플링을 다르게 해서 결과를 개선하는 것
   - 부스팅(Boosting)
   - 스태킹(Stacking)
   - 랜덤포레스트(Random Forest) : 배깅 대표 
   - 그래디언트 부스팅(Gradient Boosting) : 부스팅
   - XGBoost(eXtra Gradient Boost) : 부스팅 계열
   - LightGBM : 부스팅 계열
   - CatBoost : 부스팅 계열


### 랜덤포레스트 

### **배깅(Bagging, Bootstrap Aggregating) 방식**
#### **1. 배깅의 개념**
배깅은 **Bootstrap Aggregating**의 약자로, 다음과 같은 단계로 작동합니다:

- **부트스트래핑(Bootstrapping)**: 원본 데이터셋에서 크기가 동일한 여러 개의 샘플을 **복원 추출(With Replacement)** 방식으로 랜덤하게 생성합니다. 즉, 데이터셋에서 샘플을 무작위로 선택하여 새로운 데이터셋을 만들고, 이 과정에서 같은 샘플이 여러 번 포함될 수 있습니다.
 - 부트스트래핑은 리샘플링(샘플에서 다시 추출,,) 이걸 기반으로 해서 신뢰구간을 구하면 모집단의 신뢰구간과 동일하다
- **개별 모델 학습**: 생성된 각 부트스트랩 샘플마다 결정 트리 모델을 학습시킵니다. 이렇게 만들어진 트리들을 **배깅 트리**라고 합니다.

- **예측 결합(Aggregation)**: 예측 단계에서, 여러 트리의 예측 결과를 결합하여 최종 예측을 만듭니다. 회귀 문제의 경우 평균을 취하고, 분류 문제의 경우 다수결 투표를 사용합니다.

### **2. 랜덤 포레스트에서 배깅의 활용**

랜덤 포레스트는 배깅을 사용하여 다음과 같은 특성을 강화합니다:

- **다양성 증대**: 개별 트리의 다양성을 높이기 위해 각 트리는 서로 다른 부트스트랩 샘플로 학습됩니다. 이로 인해 트리들이 서로 다른 특성을 학습하게 되며, 과적합의 위험이 줄어듭니다.

- **과적합 방지**: 개별 트리들은 원본 데이터의 일부 샘플만을 학습하므로, 특정 데이터에 과적합되지 않도록 합니다. 또한, 랜덤 포레스트는 각 노드에서 분할할 때 랜덤하게 선택된 부분 집합의 특징 중에서 최적의 분할을 찾습니다. 이 특징의 랜덤 선택 역시 과적합을 방지하는 데 기여합니다.

- **결합 예측의 안정성**: 개별 트리들의 예측을 평균하거나 다수결로 결합함으로써, 단일 트리보다 예측이 더 안정적이고 신뢰할 수 있습니다. 이는 데이터의 노이즈에 대한 민감성을 줄여줍니다.

### **3. 랜덤 포레스트의 배깅 과정 요약**

1. **데이터 샘플링**: 원본 데이터셋에서 여러 개의 부트스트랩 샘플을 생성합니다.(랜덤하게!)
2. **트리 학습**: 각 부트스트랩 샘플로 결정 트리를 학습합니다.
   - 이때, 각 노드에서 분할을 할 때 모든 특징을 사용하는 대신, 랜덤하게 선택된 일부 특징만을 고려합니다. 이는 랜덤 포레스트의 핵심적인 차별점입니다.
3. **예측 결합**: 학습된 트리들이 새로운 데이터에 대해 예측을 수행하고, 모든 트리의 예측을 결합하여 최종 결과를 도출합니다.

랜덤 포레스트는 배깅 방식 덕분에 매우 강력한 성능을 보이며, 과적합을 잘 방지하는 동시에 안정적인 예측 결과를 제공합니다. 이 특성 때문에 다양한 데이터셋에서 널리 사용되는 앙상블 기법입니다.


 랜덤 포레스트(Random Forest)는 여러 하이퍼파라미터를 통해 모델의 성능과 복잡도를 조정할 수 있습니다. 이들 하이퍼파라미터는 모델의 학습 과정에서 중요한 역할을 하며, 적절하게 튜닝하는 것이 성능 최적화에 필수적입니다. 아래는 랜덤 포레스트의 주요 하이퍼파라미터와 그 설명입니다.

### 1. **`n_estimators` (트리의 개수)**
   - 랜덤 포레스트에서 사용할 결정 트리의 수를 지정합니다.
   - 기본적으로 트리가 많을수록 모델의 성능이 향상될 수 있지만, 학습 및 예측 시간이 길어질 수 있습니다.
   - 일반적으로 100에서 500 사이의 값을 사용하는데, 데이터에 따라 더 많은 트리를 사용할 수도 있습니다.

### 2. **`max_depth` (트리의 최대 깊이)**
   - 각 결정 트리의 최대 깊이를 설정합니다.
   - `None`으로 설정하면 트리가 리프 노드까지 성장하며, 이는 과적합의 위험이 있습니다.
   - `max_depth`를 적절하게 제한하여 트리가 너무 복잡해지는 것을 방지하고, 과적합을 방지할 수 있습니다.

### 3. **`min_samples_split` (노드를 분할하기 위한 최소 샘플 수)**
   - 노드를 분할하기 위해 필요한 최소 샘플 수를 지정합니다.
   - 이 값이 크면 트리가 적게 분할되어 덜 복잡한 모델이 됩니다.
   - 기본값은 `2`이며, 과적합을 방지하려면 값을 더 크게 설정할 수 있습니다.

### 4. **`min_samples_leaf` (리프 노드에 있어야 하는 최소 샘플 수)**
   - 리프 노드에 포함되어야 하는 최소 샘플 수를 지정합니다.
   - 이 값이 크면 리프 노드가 적게 생성되어 모델의 복잡도가 낮아집니다.
   - 과적합을 방지하는 데 유용하며, 샘플 수가 적은 노드를 방지합니다.

### 5. **`max_features` (최대 특징 수)**
   - 각 노드에서 분할할 때 고려할 최대 특징 수를 지정합니다.
   - `None`으로 설정하면 모든 특징을 사용하며, `sqrt`는 전체 특징의 제곱근, `log2`는 전체 특징의 로그, 또는 특정 정수 값을 사용할 수 있습니다.
   - 작은 값일수록 개별 트리 간의 다양성이 증가하여 과적합을 방지할 수 있습니다.

### 6. **`bootstrap` (부트스트랩 샘플링 여부)**
   - `True`로 설정하면 부트스트랩 샘플링을 사용하여 트리를 학습합니다.
   - `False`로 설정하면 전체 데이터셋을 사용하여 트리를 학습합니다.
   - 기본적으로 `True`로 설정되며, 부트스트랩 샘플링은 랜덤 포레스트의 특성을 잘 살릴 수 있게 합니다.

### 7. **`oob_score` (Out-of-Bag 샘플로 검증 여부)**
   - `True`로 설정하면 부트스트랩 샘플링에서 선택되지 않은 샘플들(out-of-bag)을 사용해 모델 성능을 평가합니다.
   - 별도의 검증 세트를 사용하지 않고도 모델의 성능을 평가할 수 있습니다.

### 8. **`n_jobs` (병렬 처리 시 사용될 코어 수)**
   - 모델 학습 및 예측 시 병렬 처리에 사용할 CPU 코어 수를 지정합니다.
   - `-1`로 설정하면 모든 코어를 사용하며, 학습 속도가 빨라집니다.

### 9. **`random_state` (랜덤 시드)**
   - 랜덤성을 제어하여 결과를 재현 가능하게 하기 위해 사용됩니다.
   - 특정 값을 지정하면 매번 동일한 결과를 얻을 수 있습니다.

### 10. **`max_leaf_nodes` (리프 노드의 최대 수)**
   - 리프 노드의 최대 수를 제한하여 트리의 복잡도를 제어합니다.
   - 리프 노드 수가 지정된 값 이상 생성되지 않도록 트리 성장이 중지됩니다.

### 11. **`class_weight` (클래스 가중치)**
   - 클래스 불균형 문제를 해결하기 위해 사용됩니다.
   - `balanced`로 설정하면 데이터셋의 클래스 분포에 따라 가중치를 자동으로 조정합니다.

### **하이퍼파라미터 튜닝 방법**
랜덤 포레스트의 하이퍼파라미터는 모델의 성능에 큰 영향을 미치기 때문에 최적의 값을 찾는 것이 중요합니다. 이를 위해 그리드 서치(Grid Search), 랜덤 서치(Random Search), 또는 베이지안 최적화(Bayesian Optimization)와 같은 방법을 사용할 수 있습니다.

적절한 하이퍼파라미터 튜닝을 통해 랜덤 포레스트의 성능을 최적화하면, 매우 강력한 예측 모델을 만들 수 있습니다.