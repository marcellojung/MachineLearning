### 분류 지표

1.  정확도 : 직관적이다. 하지만 이진 분류의 경우 데이터 구성에 따라 머신러닝 성능을 왜곡 가능

- 신용도 정확도 관련해서도...
- 타이타닉에서도 여성은 모두 생존으로 판별함

2.  이진분류에서 사용되는 오차행렬

- 오차행렬 : 4분면으로 어떤 유형의 예측 오류가 발생하는지 나타내는 지표입니다
  TP는 True positive의 약자로, 실제 True인데, 분류모델에서 예측이 True라고 판단된 경우이다.
  TN는 True negative의 약자로, 실제 False인데, 분류모델에서 예측이 False라고 판단된 경우이다.
  FP는 False positive의 약자로, 실제 False인데, 분류모델에서 예측이 True라고 판단된 경우이다.
  FN는 False negative의 약자로, 실제 True인데, 분류모델에서 예측이 False라고 판단된 경우이다.
- 정확도 = (TP+TN) / (TP+TN+FP+FN)
- 정밀도 = TP / (TP+FP) : 예측을 positive로 한 대상 중 예측과 실제값이 실제 positive한 데이터의 비율
  - sikitLearn : precision_score, 실제 음성인 데이터를 양성으로 잘못 예측하면 큰일나는 경우 : 스팸메일
- 재현율 = TP / (TP+FN) : 실제 값이 positive인 대상 중에 예측과 실제 값이 positive인 데이터의 비율
  - recall_score() : 실제 양성인 데이터를 음성으로 잘못예측하면 큰일나는 경우 : 암진단, 금융사기 판별

: 정밀도와 재현율은 상호보완적임. (정밀도-재현율 트레이드 오프 ) 그래서 임계값을 정해놓는다..
: 분류결정 임계값이 낮아질수록 positive로 예측할 확률이 높아짐. 따라서 재현율이 증가한다.
: 사이킷 런에서는 predict_proba()가 결정예측확률은 반환한다
분류 결정 임계값이 낮아지면 재현율(Recall)은 일반적으로 증가합니다.
재현율은 실제로 양성인 데이터 중에서 모델이 양성으로 올바르게 예측한 비율을 의미합니다. 임계값이 낮아지면 모델이 양성 클래스로 예측하는 기준이 완화되기 때문에, 더 많은 데이터가 양성으로 예측됩니다. 이로 인해 실제 양성 데이터를 놓칠 가능성이 줄어들어 재현율이 높아지게 됩니다.
다만, 임계값이 너무 낮아지면 양성으로 잘못 예측하는 경우도 늘어나므로, 재현율이 높아지는 대신 정밀도(Precision)가 낮아질 수 있습니다.

- 정밀도와 재현율도 맹점이 있다
- 정밀도를 100%로 만드는 법 : 확실할때만 positive
- 재현율을 100%로 만드는 방법 : 모든 환자를 positive로 예측
  -> F1 스코어로 해결 : 둘다 본다.
- F1 스코어 = 2 _ (정밀도 _ 재현율) / (정밀도 + 재현율)

- ROC, AUC :

1. ROC (Receiver Operating Characteristic) Curve
   ROC 곡선은 분류 모델의 성능을 시각적으로 평가하는 그래프입니다. 이 그래프는 **True Positive Rate (TPR)**와 **False Positive Rate (FPR)**의 변화를 보여줍니다.

- True Positive Rate (TPR): 재현율(Recall)이라고도 하며, 실제 양성인 샘플 중에서 모델이 올바르게 양성으로 예측한 비율입니다.
- False Positive Rate (FPR): 실제 음성인 샘플 중에서 모델이 잘못 양성으로 예측한 비율입니다.
  ROC 곡선은 FPR을 X축에, TPR을 Y축에 두고 임계값을 변경하면서 그린 곡선입니다. 이 곡선이 왼쪽 위 코너에 가까울수록 분류기가 더 좋은 성능을 보이는 것입니다.
  -> FPR은 빨리 떨어질수록, TPR을 빨리 버틸수록 좋은 모델. 

2. AUC (Area Under the Curve)
   AUC는 ROC 곡선 아래의 면적을 의미합니다. AUC 값은 0과 1 사이의 값이며, 이 값이 클수록 모델의 분류 성능이 우수함을 나타냅니다.
   AUC = 1: 완벽한 모델. 양성 클래스와 음성 클래스를 100% 구분할 수 있습니다.  1에 가까울 수록 좋은 수치 
   AUC = 0.5: 무작위 예측. 모델이 아무런 분류 능력이 없음을 의미합니다.
   AUC < 0.5: 모델이 오히려 잘못된 예측을 하고 있음을 나타냅니다.
   AUC는 모델이 임의의 양성 샘플과 임의의 음성 샘플을 선택했을 때, 양성 샘플의 예측 확률이 음성 샘플보다 높을 확률을 의미합니다. AUC 값이 0.5 이상이면, 모델이 어느 정도의 분류 능력을 갖추고 있음을 의미합니다.
   https://www.google.com/imgres?q=roc%20auc%20설명&imgurl=https%3A%2F%2Fvelog.velcdn.com%2Fimages%2Fzxxzx1515%2Fpost%2Fa1114a22-b77a-4325-a02d-cb41ab079312%2Fimage.png&imgrefurl=https%3A%2F%2Fvelog.io%2F%40zxxzx1515%2FAUROC-AUC-ROC-%25EC%259D%25B4%25ED%2595%25B4%25ED%2595%2598%25EA%25B8%25B0&docid=BzfpAmK8WNDVWM&tbnid=2ak97qU52CyYUM&vet=12ahUKEwiS9eSXo_uHAxUzbfUHHWPcHxsQM3oECHkQAA..i&w=1024&h=1024&hcb=2&ved=2ahUKEwiS9eSXo_uHAxUzbfUHHWPcHxsQM3oECHkQAA


### 퍼미안 인디언 당요병 예측
로지스틱 회귀에서는 **`StandardScaler`**를 주로 사용합니다. 이 스케일러는 각 특징의 평균을 0, 표준 편차를 1로 변환하여 데이터를 표준화합니다.
### 이유:
1. **경사 하강법의 성능 향상**: 로지스틱 회귀는 경사 하강법(Gradient Descent)을 사용하여 최적의 매개변수를 찾습니다. 이때, 데이터가 표준화되어 있으면 경사 하강법이 더 빠르게 수렴할 수 있습니다. 이는 모든 특징이 같은 스케일을 가지기 때문에 학습 과정에서 특정 특징이 지나치게 큰 영향을 미치는 것을 방지할 수 있기 때문입니다.

2. **가중치 해석의 용이성**: 스케일링을 통해 각 특징이 동일한 단위로 변환되면, 로지스틱 회귀 모델의 가중치를 해석하기가 더 쉬워집니다. 가중치는 각 특징이 출력에 미치는 상대적인 영향을 나타내는데, 스케일링을 통해 특징의 크기에 따른 가중치의 왜곡을 줄일 수 있습니다.

### 다른 스케일러:
- **`MinMaxScaler`**: 모든 특징을 0과 1 사이의 값으로 변환합니다. 로지스틱 회귀에서는 주로 사용되지는 않지만, 특징이 서로 다른 단위를 가지거나 양의 값으로만 존재해야 하는 경우에 유용할 수 있습니다.

- **`RobustScaler`**: 이상치(Outlier)가 있는 경우 사용합니다. 중앙값(median)과 IQR(Interquartile Range)을 사용해 스케일링을 하기 때문에, 이상치의 영향을 덜 받습니다.

하지만 일반적으로 로지스틱 회귀에서는 `StandardScaler`를 사용하는 것이 가장 흔하고 적절한 선택입니다.

바이어나이저를 이용 , 임계값을 바꿔가면서 테스트 
Binarizer"는 데이터를 이진화(binary)하는 데 사용되는 스케일러입니다. 이진화는 연속형 데이터를 0 또는 1로 변환하는 과정입니다. 이 과정은 주로 이진 분류 문제에서 사용됩니다.

Binarizer의 동작 원리:
임계값 설정: Binarizer는 주어진 임계값(threshold)보다 큰 값은 1로, 작거나 같은 값은 0으로 변환합니다.
예시: 임계값이 0.5로 설정된 경우, 입력 값이 0.5보다 크면 1로, 작거나 같으면 0으로 변환됩니다.
사용 사례:
특징의 이진화: 연속형 특징을 이진형으로 변환할 때 사용됩니다. 예를 들어, 학생의 성적이 70점을 넘으면 1, 넘지 않으면 0으로 변환하는 경우입니다.
이미지 처리: 이미지의 픽셀 값을 이진화하여 단순화된 이미지 표현을 생성하는 데 사용할 수 있습니다.
모델의 해석: 모델이 특정 임계값을 기준으로 이진 결정을 내리도록 할 때, Binarizer를 사용할 수 있습니다.